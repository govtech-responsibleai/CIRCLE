# CIRCLE: Code Interpreter Resiliency Check for LLM Exploits

## ğŸ› ï¸ Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/yourusername/CIRCLE.git
   cd CIRCLE
   ```

2. **Set up virtual environment**:
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure API keys**:
   Set the following environment variables based on `.env-template`

## ğŸ® Usage

### Basic Usage

Run benchmarks for a specific model:
```bash
python experiment.py "gpt-4.1-2025-04-14"
```

### Command Line Options

```bash
python experiment.py MODEL_NAME [OPTIONS]

Options:
  --lite        Run in lite mode (direct prompts only)
  --verbose     Enable verbose logging to console
  --test        Run in test mode (limited prompts for testing)
```

### Batch Processing

Use the provided shell script to run benchmarks for multiple models:
```bash
chmod +x run.sh
./run.sh
```

## ğŸ—ï¸ Project Structure

```
CIRCLE/
â”œâ”€â”€ experiment.py           # Main benchmarking script
â”œâ”€â”€ run.sh                 # Batch execution script
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ full_benchmark_dataset.csv  # Complete test dataset
â”œâ”€â”€ utils/                 # Utility modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ judge.py          # Response judging logic
â”‚   â”œâ”€â”€ llm.py            # LLM API interfaces
â”‚   â”œâ”€â”€ summary.py        # Result summarization
â”‚   â””â”€â”€ system_prompts.py # System prompts
â”œâ”€â”€ results/              # Output directory
â”œâ”€â”€ data/                 # Additional data files
â””â”€â”€ analysis.ipynb       # Analysis notebook
```
